{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple 3-gram Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "# Helper libraries for this notebook\n",
    "import ngram_lm\n",
    "import ngram_utils\n",
    "from shared_lib import utils, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation per character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeChinese(input_file, output_file):\n",
    "    with open(output_file, \"w\") as target_file:\n",
    "        for line in open(input_file, \"r\").readlines():\n",
    "            line = line.strip().decode(\"utf-8\")\n",
    "            output = ''\n",
    "            for c in line:\n",
    "                if c.encode('utf-8').isalnum():\n",
    "                    if len(output) > 0 and not output[-1].isalnum():\n",
    "                        output += ' '\n",
    "                    output += c.encode('utf-8')\n",
    "                else:\n",
    "                    output += ' '+c.encode('utf-8')\n",
    "            target_file.write(' '.join(output.split()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizeChinese(\"data/train.zh\", \"data/train.tok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9903244,)\n"
     ]
    }
   ],
   "source": [
    "sent_arr = []\n",
    "for line in open(\"data/train.tok\", \"r\").readlines():\n",
    "    line = line.strip()\n",
    "    words = line.split()\n",
    "    sent_arr.append(words)\n",
    "    \n",
    "sentences = np.asarray(sent_arr)\n",
    "print sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary\n",
    "\n",
    "Set vocabulary size = 50000. Other word will be marked as `<unk>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set vocabulary: 50000 words\n"
     ]
    }
   ],
   "source": [
    "V=50000\n",
    "vocab = vocabulary.Vocabulary((utils.canonicalize_word(w) for w in utils.flatten(sentences)), size=V)\n",
    "print \"Train set vocabulary: %d words\" % vocab.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/vocab.pkl', 'wb') as output:\n",
    "    dill.dump(vocab, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Our smoothed models will be trigram models, so for convenience we'll prepend *two* `<s>` markers.\n",
    "\n",
    "To make it easier to work with, we'll take the list of tokens as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_to_tokens(sents):\n",
    "    \"\"\"Returns an flattened list of the words in the sentences, with padding for a trigram model.\"\"\"\n",
    "    padded_sentences = ([\"<s>\", \"<s>\"] + s + [\"</s>\"] for s in sents)\n",
    "    # This will canonicalize words, and replace anything not in vocab with <unk>\n",
    "    return np.array([utils.canonicalize_word(w, wordset=vocab.wordset) \n",
    "                     for w in utils.flatten(padded_sentences)], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = sents_to_tokens(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: \n",
      "array(['<s>', '<s>', '\\xe4\\xb8\\x80', '\\xe5\\xaf\\xb9', '\\xe4\\xb8\\xb9',\n",
      "       '\\xe9\\xa1\\xb6', '\\xe9\\xb9\\xa4', '\\xe6\\xad\\xa3', '\\xe7\\x9b\\x91',\n",
      "       '\\xe8\\xa7\\x86', '\\xe7\\x9d\\x80', '\\xe5\\xae\\x83', '\\xe4\\xbb\\xac',\n",
      "       '\\xe7\\x9a\\x84', '\\xe7\\xad\\x91', '\\xe5\\xb7\\xa2', '\\xe9\\xa2\\x86',\n",
      "       '\\xe5\\x9c\\xb0', '</s>', '<s>'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print \"Sample data: \\n\" + repr(train_tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trigram LM... done in 1144.55 s\n",
      "=== N-gram Language Model stats ===\n",
      "50000 unique 1-grams\n",
      "2.62925e+06 unique 2-grams\n",
      "2.1179e+07 unique 3-grams\n",
      "Optimal memory usage (counts only): 475 MB\n"
     ]
    }
   ],
   "source": [
    "import ngram_lm\n",
    "reload(ngram_lm)\n",
    "\n",
    "# Switch between different smooth mode\n",
    "# Model = ngram_lm.AddKTrigramLM\n",
    "Model = ngram_lm.KNTrigramLM\n",
    "\n",
    "t0 = time.time()\n",
    "print \"Building trigram LM...\",\n",
    "lm = Model(train_tokens)\n",
    "print \"done in %.02f s\" % (time.time() - t0)\n",
    "ngram_utils.print_stats(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/lm.pkl', 'wb') as output:\n",
    "    dill.dump(lm, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change `params` to change the smoothing factor. `AddKTrigramLM` will ignore the value of `delta`, \n",
    "#and `KNTrigramLM` will ignore `k`.\n",
    "#lm.set_live_paramsset_liv (k = 0.001, delta=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring on Held-Out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train perplexity: 33.21\n"
     ]
    }
   ],
   "source": [
    "log_p_data, num_real_tokens = ngram_utils.score_seq(lm, train_tokens)\n",
    "print \"Train perplexity: %.02f\" % (2**(-1*log_p_data/num_real_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> <s> 小 陈 教 授 权 并 非 是 谁 ？ </s>\n",
      "[10 tokens; log P(seq): -63.95]\n",
      "\n",
      "<s> <s> 科 洛 依 德 博 士 </s>\n",
      "[6 tokens; log P(seq): -25.80]\n",
      "\n",
      "<s> <s> 我 们 要 去 。 </s>\n",
      "[5 tokens; log P(seq): -18.53]\n",
      "\n",
      "<s> <s> 尽 管 第 一 次 经 历 过 传 送 器 ” 与 “ 别 提 这 些 礼 物\n",
      "[20 tokens; log P(seq): -104.52]\n",
      "\n",
      "<s> <s> 别 担 心 热 点 。 </s>\n",
      "[6 tokens; log P(seq): -31.40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_length = 20\n",
    "num_sentences = 5\n",
    "\n",
    "for _ in range(num_sentences):\n",
    "    seq = [\"<s>\", \"<s>\"]\n",
    "    for i in range(max_length):\n",
    "        seq.append(ngram_utils.predict_next(lm, seq))\n",
    "        # Stop at end-of-sentence.\n",
    "        if seq[-1] == \"</s>\": break\n",
    "    print \" \".join(seq)\n",
    "    print \"[{1:d} tokens; log P(seq): {0:.02f}]\".format(*ngram_utils.score_seq(lm, seq))\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
